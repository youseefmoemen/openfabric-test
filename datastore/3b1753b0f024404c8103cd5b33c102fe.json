{"ray": {"sid": "fec31a36eea34b46af68d7425b32e469", "uid": null, "qid": "3b1753b0f024404c8103cd5b33c102fe", "rid": null, "bars": {"default": {"percent": "100", "remaining": "0"}}, "messages": [{"type": "ERROR", "content": "process - failed executing: [3b1753b0f024404c8103cd5b33c102fe]\nTraceback (most recent call last):\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/openfabric_pysdk/app/worker.py\", line 90, in process\n    output = execution_callback_function(data, ray, self.state)\n  File \"/home/youseef/openfabric/openfabric-ai-software-engineer/openfabric-ai-software-engineer/main.py\", line 84, in execute\n    answer = qa_model(text, context)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/youseef/openfabric/openfabric-ai-software-engineer/openfabric-ai-software-engineer/main.py\", line 54, in forward\n    outputs = self.model.generate(**inputs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/transformers/generation/utils.py\", line 1593, in generate\n    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/transformers/generation/utils.py\", line 742, in _prepare_encoder_decoder_kwargs_for_generation\n    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/accelerate/hooks.py\", line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\", line 1110, in forward\n    layer_outputs = layer_module(\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/accelerate/hooks.py\", line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\", line 694, in forward\n    self_attention_outputs = self.layer[0](\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/accelerate/hooks.py\", line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\", line 601, in forward\n    attention_output = self.SelfAttention(\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/accelerate/hooks.py\", line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\", line 520, in forward\n    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/accelerate/hooks.py\", line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/bitsandbytes/nn/modules.py\", line 450, in forward\n    out = bnb.matmul(x, self.weight, bias=self.bias, state=self.state)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py\", line 562, in matmul\n    return MatMul8bitLt.apply(A, B, out, bias, state)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/autograd/function.py\", line 539, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py\", line 297, in forward\n    using_igemmlt = supports_igemmlt(A.device) and not state.force_no_igemmlt\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py\", line 227, in supports_igemmlt\n    if torch.cuda.get_device_capability(device=device) < (7, 5):\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 435, in get_device_capability\n    prop = get_device_properties(device)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 450, in get_device_properties\n    device = _get_device_index(device, optional=True)\n  File \"/home/youseef/anaconda3/envs/openfabric/lib/python3.8/site-packages/torch/cuda/_utils.py\", line 35, in _get_device_index\n    raise ValueError(f\"Expected a cuda device, but got: {device}\")\nValueError: Expected a cuda device, but got: cpu\n", "created_at": "2023-12-14T03:25:09.198246"}], "status": "FAILED", "created_at": "2023-12-14T03:24:57.539627", "updated_at": "2023-12-14T03:25:09.199594", "finished": true}, "in": {"text": ["What is the capital of Egypt?"]}, "out": {}}